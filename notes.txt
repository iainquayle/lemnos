changes:
	guarenteed:
		move padding to before dilation, maybe even stride too
		make mix conv transform
			set it up so that it is just an enum flag in the conv module, nothing else changes
			to achieve with torch, use torch map, on each batch channel, with a tensor of longs that are the indices
		rework the torch formatters
			make get source and module to the formatter obj
			change how the optimizer is inited, maybe make some base class
				little overkill but cleanest by far
	possible:
		move conformance to its own module, then allow components to pull it in
			perhaps put it under shared
			perhpas rename shared to shape, as that seems to be the only thing it holds
		add a divisor option to the clamp val on shape bounds
		make it so the divisor lookahead doesnt take into account the nodes hint
		rename transitions to edges or something?
		make more rigorous gc collection, memory fills up fast

problems:

