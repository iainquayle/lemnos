changes:
	guarenteed:
		make control framework agnostic
			design below
		move padding to before dilation, maybe even stride too
		make mix conv transform
			to achieve with torch, use torch map, on each batch channel, with a tensor of longs that are the indices
	possible:
		move growth functions to the transitions
			probably makes more sense, cant find a reason why it shouldnt be done 
			make it so that if the transition group has more or less children, the same throughput is maintained
			could add optional shape bounds to the transition
		move conformance to its own module, then allow components to pull it in
			perhaps put it under shared
			perhpas rename shared to shape, as that seems to be the only thing it holds
		reorganize the modules
			components and compile in their own modules
		add a divisor option to the clamp val on shape bounds
		make it so the divisor lookahead doesnt take into account the nodes hint

problems:
	memory leak somewhere, likely something to do with metrics, need to find it	

design:
	components < schema graph < compile < schema < adapter < control
	adapters
		allow this to work with any framework
		currently, using isinstance, but could use a nice approach
			look into the action/command? pattern and the visitor pattern, may provide some better structural ideas?
	make control agnostic
		start by making control specific to torch, but attempt to make it more generic later and accept an adapter
		adapter will use the source gen target and functions specific to the framework for training
		though this may be a dumb idea or atleast the sin of premature planning
	transitions:
		are not split into different types as the coordination is done by compile modules
		they would otherwise need take in data from the compile module to decide what node to return

control split
	make a model train and eval interface to inherit from
	move everything to do with training and validating to its own modules
	perhaps make a builder, which can have ir passed in, gives back a module
