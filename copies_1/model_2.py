import torch
class M2(torch.nn.Module):
	def __init__(self):
		super().__init__()
		import torch
		self.c0000_1 = torch.nn.Conv1d(56, 15, (1,), (1,), (0,), (1,), 1, bias=True, padding_mode='zeros')
		self.c0000_2 = torch.nn.ReLU6()
		self.c0000_3 = torch.nn.BatchNorm1d(15)
		self.c0001_1 = torch.nn.BatchNorm1d(15)
		self.c0002_1 = torch.nn.Conv1d(15, 16, (2,), (2,), (0,), (1,), 1, bias=True, padding_mode='zeros')
		self.c0002_2 = torch.nn.ReLU6()
		self.c0002_3 = torch.nn.BatchNorm1d(16)
		self.c0003_1 = torch.nn.BatchNorm1d(16)
		self.c0004_1 = torch.nn.Conv1d(16, 63, (1,), (1,), (0,), (1,), 1, bias=True, padding_mode='zeros')
		self.c0004_2 = torch.nn.ReLU6()
		self.c0004_3 = torch.nn.BatchNorm1d(63)
		self.c0005_1 = torch.nn.Conv1d(63, 63, (7,), (1,), (3,), (1,), 63, bias=True, padding_mode='zeros')
		self.c0005_2 = torch.nn.ReLU6()
		self.c0005_3 = torch.nn.BatchNorm1d(63)
		self.c0006_1 = torch.nn.Conv1d(63, 16, (1,), (1,), (0,), (1,), 1, bias=True, padding_mode='zeros')
		self.c0006_2 = torch.nn.BatchNorm1d(16)
		self.c0007_1 = torch.nn.BatchNorm1d(16)
		self.c0008_1 = torch.nn.Conv1d(16, 16, (2,), (2,), (0,), (1,), 1, bias=True, padding_mode='zeros')
		self.c0008_2 = torch.nn.ReLU6()
		self.c0008_3 = torch.nn.BatchNorm1d(16)
		self.c0009_1 = torch.nn.BatchNorm1d(16)
		self.c000a_1 = torch.nn.Conv1d(16, 26, (1,), (1,), (0,), (1,), 1, bias=True, padding_mode='zeros')
		self.c000a_2 = torch.nn.ReLU6()
		self.c000a_3 = torch.nn.BatchNorm1d(26)
		self.c000b_1 = torch.nn.Conv1d(26, 26, (7,), (1,), (3,), (1,), 26, bias=True, padding_mode='zeros')
		self.c000b_2 = torch.nn.ReLU6()
		self.c000b_3 = torch.nn.BatchNorm1d(26)
		self.c000c_1 = torch.nn.Conv1d(26, 16, (1,), (1,), (0,), (1,), 1, bias=True, padding_mode='zeros')
		self.c000c_2 = torch.nn.BatchNorm1d(16)
		self.c000d_1 = torch.nn.BatchNorm1d(16)
		self.c000e_1 = torch.nn.Conv1d(16, 60, (1,), (1,), (0,), (1,), 1, bias=True, padding_mode='zeros')
		self.c000e_2 = torch.nn.ReLU6()
		self.c000e_3 = torch.nn.BatchNorm1d(60)
		self.c000f_1 = torch.nn.Conv1d(60, 60, (7,), (1,), (3,), (1,), 60, bias=True, padding_mode='zeros')
		self.c000f_2 = torch.nn.ReLU6()
		self.c000f_3 = torch.nn.BatchNorm1d(60)
		self.c0010_1 = torch.nn.Conv1d(60, 16, (1,), (1,), (0,), (1,), 1, bias=True, padding_mode='zeros')
		self.c0010_2 = torch.nn.BatchNorm1d(16)
		self.c0011_1 = torch.nn.BatchNorm1d(16)
		self.c0012_1 = torch.nn.Conv1d(16, 19, (2,), (2,), (0,), (1,), 1, bias=True, padding_mode='zeros')
		self.c0012_2 = torch.nn.ReLU6()
		self.c0012_3 = torch.nn.BatchNorm1d(19)
		self.c0013_1 = torch.nn.BatchNorm1d(19)
		self.c0014_1 = torch.nn.Conv1d(19, 45, (1,), (1,), (0,), (1,), 1, bias=True, padding_mode='zeros')
		self.c0014_2 = torch.nn.ReLU6()
		self.c0014_3 = torch.nn.BatchNorm1d(45)
		self.c0015_1 = torch.nn.Conv1d(45, 45, (7,), (1,), (3,), (1,), 45, bias=True, padding_mode='zeros')
		self.c0015_2 = torch.nn.ReLU6()
		self.c0015_3 = torch.nn.BatchNorm1d(45)
		self.c0016_1 = torch.nn.Conv1d(45, 19, (1,), (1,), (0,), (1,), 1, bias=True, padding_mode='zeros')
		self.c0016_2 = torch.nn.BatchNorm1d(19)
		self.c0017_1 = torch.nn.BatchNorm1d(19)
		self.c0018_1 = torch.nn.Conv1d(19, 40, (1,), (1,), (0,), (1,), 1, bias=True, padding_mode='zeros')
		self.c0018_2 = torch.nn.ReLU6()
		self.c0018_3 = torch.nn.BatchNorm1d(40)
		self.c0019_1 = torch.nn.Conv1d(40, 40, (7,), (1,), (3,), (1,), 40, bias=True, padding_mode='zeros')
		self.c0019_2 = torch.nn.ReLU6()
		self.c0019_3 = torch.nn.BatchNorm1d(40)
		self.c001a_1 = torch.nn.Conv1d(40, 19, (1,), (1,), (0,), (1,), 1, bias=True, padding_mode='zeros')
		self.c001a_2 = torch.nn.BatchNorm1d(19)
		self.c001b_1 = torch.nn.BatchNorm1d(19)
		self.c001c_1 = torch.nn.Conv1d(19, 44, (1,), (1,), (0,), (1,), 1, bias=True, padding_mode='zeros')
		self.c001c_2 = torch.nn.ReLU6()
		self.c001c_3 = torch.nn.BatchNorm1d(44)
		self.c001d_1 = torch.nn.Conv1d(44, 44, (7,), (1,), (3,), (1,), 44, bias=True, padding_mode='zeros')
		self.c001d_2 = torch.nn.ReLU6()
		self.c001d_3 = torch.nn.BatchNorm1d(44)
		self.c001e_1 = torch.nn.Conv1d(44, 19, (1,), (1,), (0,), (1,), 1, bias=True, padding_mode='zeros')
		self.c001e_2 = torch.nn.BatchNorm1d(19)
		self.c001f_1 = torch.nn.BatchNorm1d(19)
		self.c0020_1 = torch.nn.Conv1d(19, 22, (2,), (2,), (0,), (1,), 1, bias=True, padding_mode='zeros')
		self.c0020_2 = torch.nn.ReLU6()
		self.c0020_3 = torch.nn.BatchNorm1d(22)
		self.c0021_1 = torch.nn.Conv1d(22, 42, (2,), (2,), (0,), (1,), 1, bias=True, padding_mode='zeros')
		self.c0021_2 = torch.nn.ReLU6()
		self.c0021_3 = torch.nn.BatchNorm1d(42)
		self.c0022_1 = torch.nn.BatchNorm1d(42)
		self.c0023_1 = torch.nn.Conv1d(42, 46, (2,), (2,), (0,), (1,), 1, bias=True, padding_mode='zeros')
		self.c0023_2 = torch.nn.ReLU6()
		self.c0023_3 = torch.nn.BatchNorm1d(46)
		self.c0024_1 = torch.nn.Conv1d(46, 74, (2,), (2,), (0,), (1,), 1, bias=True, padding_mode='zeros')
		self.c0024_2 = torch.nn.ReLU6()
		self.c0024_3 = torch.nn.BatchNorm1d(74)
		self.c0025_1 = torch.nn.BatchNorm1d(74)
		self.c0026_1 = torch.nn.Conv1d(74, 265, (1,), (1,), (0,), (1,), 1, bias=True, padding_mode='zeros')
		self.c0026_2 = torch.nn.ReLU6()
		self.c0026_3 = torch.nn.BatchNorm1d(265)
		self.c0027_1 = torch.nn.Conv1d(265, 265, (7,), (1,), (3,), (1,), 265, bias=True, padding_mode='zeros')
		self.c0027_2 = torch.nn.ReLU6()
		self.c0027_3 = torch.nn.BatchNorm1d(265)
		self.c0028_1 = torch.nn.Conv1d(265, 74, (1,), (1,), (0,), (1,), 1, bias=True, padding_mode='zeros')
		self.c0028_2 = torch.nn.BatchNorm1d(74)
		self.c0029_1 = torch.nn.BatchNorm1d(74)
		self.c002a_1 = torch.nn.Conv1d(74, 217, (1,), (1,), (0,), (1,), 1, bias=True, padding_mode='zeros')
		self.c002a_2 = torch.nn.ReLU6()
		self.c002a_3 = torch.nn.BatchNorm1d(217)
		self.c002b_1 = torch.nn.Conv1d(217, 217, (7,), (1,), (3,), (1,), 217, bias=True, padding_mode='zeros')
		self.c002b_2 = torch.nn.ReLU6()
		self.c002b_3 = torch.nn.BatchNorm1d(217)
		self.c002c_1 = torch.nn.Conv1d(217, 74, (1,), (1,), (0,), (1,), 1, bias=True, padding_mode='zeros')
		self.c002c_2 = torch.nn.BatchNorm1d(74)
		self.c002d_1 = torch.nn.BatchNorm1d(74)
		self.c002e_1 = torch.nn.Conv1d(74, 52, (2,), (2,), (0,), (1,), 1, bias=True, padding_mode='zeros')
		self.c002e_2 = torch.nn.ReLU6()
		self.c002e_3 = torch.nn.BatchNorm1d(52)
		self.c002f_1 = torch.nn.Linear(52, 1, bias=True)
	def forward(self, r0001):
		import torch
		r0001 = r0001.view(-1, 14336)
		r0001 = self.c0000_3(self.c0000_2(self.c0000_1(r0001.view(-1, 56, 256)))).view(-1, 3840)
		r0001 = self.c0001_1(r0001.view(-1, 15, 256)).view(-1, 3840)
		r0001 = self.c0002_3(self.c0002_2(self.c0002_1(r0001.view(-1, 15, 256)))).view(-1, 2048)
		r0001 = self.c0003_1(r0001.view(-1, 16, 128)).view(-1, 2048)
		r0002 = self.c0004_3(self.c0004_2(self.c0004_1(r0001.view(-1, 16, 128)))).view(-1, 8064)
		r0002 = self.c0005_3(self.c0005_2(self.c0005_1(r0002.view(-1, 63, 128)))).view(-1, 8064)
		r0002 = self.c0006_2(self.c0006_1(r0002.view(-1, 63, 128))).view(-1, 2048)
		r0002 = self.c0007_1((r0001 + r0002).view(-1, 16, 128)).view(-1, 2048)
		r0002 = self.c0008_3(self.c0008_2(self.c0008_1(r0002.view(-1, 16, 128)))).view(-1, 1024)
		r0002 = self.c0009_1(r0002.view(-1, 16, 64)).view(-1, 1024)
		r0001 = self.c000a_3(self.c000a_2(self.c000a_1(r0002.view(-1, 16, 64)))).view(-1, 1664)
		r0001 = self.c000b_3(self.c000b_2(self.c000b_1(r0001.view(-1, 26, 64)))).view(-1, 1664)
		r0001 = self.c000c_2(self.c000c_1(r0001.view(-1, 26, 64))).view(-1, 1024)
		r0001 = self.c000d_1((r0002 + r0001).view(-1, 16, 64)).view(-1, 1024)
		r0002 = self.c000e_3(self.c000e_2(self.c000e_1(r0001.view(-1, 16, 64)))).view(-1, 3840)
		r0002 = self.c000f_3(self.c000f_2(self.c000f_1(r0002.view(-1, 60, 64)))).view(-1, 3840)
		r0002 = self.c0010_2(self.c0010_1(r0002.view(-1, 60, 64))).view(-1, 1024)
		r0002 = self.c0011_1((r0001 + r0002).view(-1, 16, 64)).view(-1, 1024)
		r0002 = self.c0012_3(self.c0012_2(self.c0012_1(r0002.view(-1, 16, 64)))).view(-1, 608)
		r0002 = self.c0013_1(r0002.view(-1, 19, 32)).view(-1, 608)
		r0001 = self.c0014_3(self.c0014_2(self.c0014_1(r0002.view(-1, 19, 32)))).view(-1, 1440)
		r0001 = self.c0015_3(self.c0015_2(self.c0015_1(r0001.view(-1, 45, 32)))).view(-1, 1440)
		r0001 = self.c0016_2(self.c0016_1(r0001.view(-1, 45, 32))).view(-1, 608)
		r0001 = self.c0017_1((r0002 + r0001).view(-1, 19, 32)).view(-1, 608)
		r0002 = self.c0018_3(self.c0018_2(self.c0018_1(r0001.view(-1, 19, 32)))).view(-1, 1280)
		r0002 = self.c0019_3(self.c0019_2(self.c0019_1(r0002.view(-1, 40, 32)))).view(-1, 1280)
		r0002 = self.c001a_2(self.c001a_1(r0002.view(-1, 40, 32))).view(-1, 608)
		r0002 = self.c001b_1((r0001 + r0002).view(-1, 19, 32)).view(-1, 608)
		r0001 = self.c001c_3(self.c001c_2(self.c001c_1(r0002.view(-1, 19, 32)))).view(-1, 1408)
		r0001 = self.c001d_3(self.c001d_2(self.c001d_1(r0001.view(-1, 44, 32)))).view(-1, 1408)
		r0001 = self.c001e_2(self.c001e_1(r0001.view(-1, 44, 32))).view(-1, 608)
		r0001 = self.c001f_1((r0002 + r0001).view(-1, 19, 32)).view(-1, 608)
		r0001 = self.c0020_3(self.c0020_2(self.c0020_1(r0001.view(-1, 19, 32)))).view(-1, 352)
		r0001 = self.c0021_3(self.c0021_2(self.c0021_1(r0001.view(-1, 22, 16)))).view(-1, 336)
		r0001 = self.c0022_1(r0001.view(-1, 42, 8)).view(-1, 336)
		r0001 = self.c0023_3(self.c0023_2(self.c0023_1(r0001.view(-1, 42, 8)))).view(-1, 184)
		r0001 = self.c0024_3(self.c0024_2(self.c0024_1(r0001.view(-1, 46, 4)))).view(-1, 148)
		r0001 = self.c0025_1(r0001.view(-1, 74, 2)).view(-1, 148)
		r0002 = self.c0026_3(self.c0026_2(self.c0026_1(r0001.view(-1, 74, 2)))).view(-1, 530)
		r0002 = self.c0027_3(self.c0027_2(self.c0027_1(r0002.view(-1, 265, 2)))).view(-1, 530)
		r0002 = self.c0028_2(self.c0028_1(r0002.view(-1, 265, 2))).view(-1, 148)
		r0002 = self.c0029_1((r0001 + r0002).view(-1, 74, 2)).view(-1, 148)
		r0001 = self.c002a_3(self.c002a_2(self.c002a_1(r0002.view(-1, 74, 2)))).view(-1, 434)
		r0001 = self.c002b_3(self.c002b_2(self.c002b_1(r0001.view(-1, 217, 2)))).view(-1, 434)
		r0001 = self.c002c_2(self.c002c_1(r0001.view(-1, 217, 2))).view(-1, 148)
		r0001 = self.c002d_1((r0002 + r0001).view(-1, 74, 2)).view(-1, 148)
		r0001 = self.c002e_3(self.c002e_2(self.c002e_1(r0001.view(-1, 74, 2)))).view(-1, 52)
		r0001 = self.c002f_1(r0001)
		return r0001